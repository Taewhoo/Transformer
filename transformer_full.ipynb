{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNzUT3c8cUHXur2fX0k0alJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Dataloader"],"metadata":{"id":"AVzWEa2Xw0GW"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Aar43iHicvp9","executionInfo":{"status":"ok","timestamp":1701152210009,"user_tz":-540,"elapsed":19151,"user":{"displayName":"이태후","userId":"03468433647806446322"}},"outputId":"f6544671-8ded-48fd-cf85-b1d33c013c70"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!pip install sentencepiece"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bc12tCsjmfRh","executionInfo":{"status":"ok","timestamp":1701152702623,"user_tz":-540,"elapsed":9727,"user":{"displayName":"이태후","userId":"03468433647806446322"}},"outputId":"94925cc9-86ed-404c-9347-f337f912e4e5"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting sentencepiece\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.99\n"]}]},{"cell_type":"code","source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn as nn\n","from torch.nn.functional import pad\n","from torch.utils.data.distributed import DistributedSampler\n","import sentencepiece as spm\n","import pandas as pd\n","\n","class TFDataset(Dataset):\n","\n","    def __init__(self, bpe_model, tsv_file):\n","        sp = spm.SentencePieceProcessor()\n","        sp.load(bpe_model)\n","\n","        self.sp = sp\n","        self.bos_id = sp.bos_id() #1\n","        self.eos_id = sp.eos_id() #2\n","\n","        self.tsv_file = pd.read_csv(tsv_file, delimiter='\\t', usecols=['src', 'tar'])\n","\n","    def __len__(self):\n","        return len(self.tsv_file) #250k\n","\n","    def __getitem__(self, idx):\n","        src_sent = self.tsv_file.iloc[idx, 0]\n","        tar_sent = self.tsv_file.iloc[idx, 1]\n","        src_encoded = [self.bos_id] + self.sp.encode_as_ids(src_sent) + [self.eos_id]\n","        tar_encoded = [self.bos_id] + self.sp.encode_as_ids(tar_sent) + [self.eos_id]\n","\n","        return torch.tensor(src_encoded), torch.tensor(tar_encoded)\n","\n","def collate_fn(batch, max_pad=128):\n","\n","    '''batch : [(src_tensor, tar_tensor), ...]'''\n","\n","    src_list, tar_list = [], []\n","\n","    for (src, tar) in batch:\n","        src_padded = pad(src, (0, max_pad - len(src))) # 문장 뒤로 max_len까지 zero-padding\n","        src_list.append(src_padded)\n","        tar_padded = pad(tar, (0, max_pad - len(tar)))\n","        tar_list.append(tar_padded)\n","\n","    src = torch.stack(src_list) # list([128],[128],[128]) => tensor w/ size([3,128])\n","    tar = torch.stack(tar_list)\n","\n","    return (src, tar)\n","\n","def create_dataloader(bpe_model, tsv_file, is_distributed=False, batch_size=128):\n","    dataset = TFDataset(bpe_model, tsv_file)\n","    sampler = (DistributedSampler(dataset) if is_distributed else None)\n","\n","    train_dataloader = DataLoader(\n","        dataset,\n","        batch_size=batch_size,\n","        shuffle=(is_distributed is False),\n","        sampler=sampler,\n","        collate_fn=collate_fn\n","    )\n","    return train_dataloader"],"metadata":{"id":"SGRqalejkyQ_","executionInfo":{"status":"ok","timestamp":1701154004226,"user_tz":-540,"elapsed":5879,"user":{"displayName":"이태후","userId":"03468433647806446322"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["bpe_model = \"/content/drive/MyDrive/dmis/Transformer/bpe/bpe_250k.model\"\n","tsv_path = \"/content/drive/MyDrive/dmis/Transformer/bpe/train_df_250k.tsv\""],"metadata":{"id":"Aux0If9Hm02h","executionInfo":{"status":"ok","timestamp":1701153913202,"user_tz":-540,"elapsed":348,"user":{"displayName":"이태후","userId":"03468433647806446322"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["## Embedding, Positional Encoding"],"metadata":{"id":"xEp4jVut2nsH"}},{"cell_type":"code","source":["import math\n","\n","class Embeddings(nn.Module): # dim(input/output) -> dim(d_model)\n","    def __init__(self, vocab_size, d_model):\n","        super().__init__()\n","        self.embed = nn.Embedding(vocab_size, d_model) # (vocab_size x d_model) embedding layer 생성\n","        self.d_model = d_model\n","    def forward(self, x):\n","        return self.embed(x) * math.sqrt(self.d_model)"],"metadata":{"id":"XWVfQVLgu44s","executionInfo":{"status":"ok","timestamp":1701155083036,"user_tz":-540,"elapsed":2,"user":{"displayName":"이태후","userId":"03468433647806446322"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["class PositionalEncoding(nn.Module):\n","    def __init__(self, d_model, dropout, max_len=5000):\n","        super().__init__()\n","        self.dropout = nn.Dropout(dropout)\n","\n","        pos_enc = torch.zeros(max_len, d_model) # [5000x512] (최대길이 한문장)\n","        pos = torch.arange(0, max_len).unsqueeze(1) # [max_len] -> [max_len,1] (position index)\n","        div_term = 1/torch.pow(10000, torch.arange(0, d_model, 2)/d_model) # 1/10000^(2i/d_model)\n","\n","        pos_enc[:, 0::2] = torch.sin(pos*div_term)\n","        pos_enc[:, 1::2] = torch.cos(pos*div_term)\n","        pos_enc = pos_enc.unsqueeze(0) # batch_dim, max_len, d_model\n","        self.register_buffer(\"pos_enc\", pos_enc) # pos_enc는 학습되지 않고 고정\n","\n","    def forward(self, x): # batch_dim x seq_len x d_model\n","        x = x + self.pos_enc[:, :x.size(1)].requires_grad_(False) # pos_enc[:, :seq_len] 까지 잘라서 적용\n","        return self.dropout(x)"],"metadata":{"id":"bS9ScBZcuEur","executionInfo":{"status":"ok","timestamp":1701154793448,"user_tz":-540,"elapsed":4,"user":{"displayName":"이태후","userId":"03468433647806446322"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["## Attention"],"metadata":{"id":"IzYO8Yk-27ck"}},{"cell_type":"code","source":["def attention(query, key, value, mask=None, dropout=None):\n","\n","    '''\n","    query=(1xd_k), key,value=(nxd_k)로 생각 (실제로 query도 (nxd_k) word matrix)\n","    scaling : d_k 커질수록 softmax 시 gradient saturate 방지\n","    '''\n","\n","    d_k = query.size(-1)\n","    scores = torch.matmul(query, key.transpose(-2,-1)) / math.sqrt(d_k) # score per word wrt query\n","    if mask:\n","        scores = scores.masked_fill(mask==0, -1e9) # pad masking\n","    prob = scores.softmax(dim=0)\n","    if dropout:\n","        prob = dropout(prob)\n","\n","    weighted_query = torch.matmul(prob, value)\n","\n","    return weighted_query, prob"],"metadata":{"id":"TgpL-eJ927Nv","executionInfo":{"status":"ok","timestamp":1701157032725,"user_tz":-540,"elapsed":518,"user":{"displayName":"이태후","userId":"03468433647806446322"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["import copy\n","\n","def clones(module, N):\n","    \"Produce modulelist with N identical layers.\"\n","    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"],"metadata":{"id":"LTdLZifA3FkZ","executionInfo":{"status":"ok","timestamp":1701157056001,"user_tz":-540,"elapsed":2,"user":{"displayName":"이태후","userId":"03468433647806446322"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["class MultiHeadAttention(nn.Module):\n","    def __init__(self, h, d_model, dropout=0.1):\n","        super().__init__()\n","        assert d_model % h == 0\n","\n","        self.d_model = d_model\n","        self.d_k = d_model // h\n","        self.h = h\n","        self.dropout = nn.Dropout(p=dropout)\n","        self.modulelist = clones(nn.Linear(d_model, d_model), N=4) # torch에 인식 위함, qkv 위해 3개, 마지막 위해 1개\n","        self.att_prob = None\n","\n","    def forward(self, query, key, value, mask=None):\n","        if mask:\n","            mask = mask.unsqueeze(1) # ??\n","        num_batch = query.size(0)\n","\n","        qkv_list = []\n","        for lin, x in zip(self.modulelist, (query, key, value)):\n","            qkv = lin(x).view(num_batch, -1, self.h, self.d_k).transpose(1,2)\n","            qkv_list.append(qkv)\n","\n","        weighted_query, self.att_prob = attention(query, key, value, mask=mask, dropout=self.dropout)\n","\n","        # concat\n","        weighted_query = (weighted_query.transpose(1,2).contiguous().view(num_batch, -1, self.h*self.d_k))\n","        del query\n","        del key\n","        del value\n","\n","        return self.modulelist[-1](weighted_query)"],"metadata":{"id":"WqJ2rdEX3HYY","executionInfo":{"status":"ok","timestamp":1701157064620,"user_tz":-540,"elapsed":2,"user":{"displayName":"이태후","userId":"03468433647806446322"}}},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":["## FFN"],"metadata":{"id":"_SVgppgj3rxg"}},{"cell_type":"code","source":["class PositionwiseFeedForward(nn.Module):\n","    def __init__(self, d_model, d_inner, dropout):\n","        super().__init__()\n","        self.w_1 = nn.Linear(d_model, d_inner) # linear transformation (input d -> hidden d)\n","        self.w_2 = nn.Linear(d_inner, d_model) # hidden d -> input d\n","        self.dropout = nn.Dropout(dropout) # regularization\n","\n","    def forward(self, x):\n","        return self.w_2(self.dropout(self.w_1(x).relu()))"],"metadata":{"id":"Zxp5VeBt3tbG","executionInfo":{"status":"ok","timestamp":1701157200861,"user_tz":-540,"elapsed":5,"user":{"displayName":"이태후","userId":"03468433647806446322"}}},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":["## EncoderDecoder"],"metadata":{"id":"TufYo8ut4Mo2"}},{"cell_type":"code","source":["class EncoderDecoder(nn.Module):\n","    '''A standard Encoder-Decoder architecture'''\n","    def __init__(self, encoder, decoder, src_embed, tar_embed, generator):\n","        super().__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.src_embed = src_embed\n","        self.tar_embed = tar_embed\n","        self.generator = generator\n","\n","    def encode(self, src, src_mask):\n","        return self.encoder(self.src_embed(src), src_mask)\n","\n","    def decode(self, memory, src_mask, tar, tar_mask):\n","        return self.decoder(self.tar_embed(tar), memory, src_mask, tar_mask)\n","\n","    def forward(self, src, tar, src_mask, tar_mask):\n","        return self.decode(self.encode(src, src_mask), src_mask, tar, tar_mask)"],"metadata":{"id":"rxnczXOk4N9N","executionInfo":{"status":"ok","timestamp":1701157346991,"user_tz":-540,"elapsed":2,"user":{"displayName":"이태후","userId":"03468433647806446322"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["class LayerNorm(nn.Module):\n","    '''Normalize weights (into smaller range)\n","    Formula : (x-mean) / (std+eps)\n","    '''\n","    def __init__(self, size, eps=1e-6):\n","        super().__init__()\n","        self.a_2 = nn.Parameter(torch.ones(size)) #scaling param\n","        self.b_2 = nn.Parameter(torch.zeros(size)) #bias param\n","\n","    def forward(self, x):\n","        # compute mean, std along the last dimension\n","        mean = x.mean(-1, keepdim=True)\n","        std = x.std(-1, keepdim=True)\n","\n","        return self.a_2 * (x-mean) / (std+self.eps) + self.b_2"],"metadata":{"id":"60EwRFwX4Zc-","executionInfo":{"status":"ok","timestamp":1701157380357,"user_tz":-540,"elapsed":1,"user":{"displayName":"이태후","userId":"03468433647806446322"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["class ResConnection(nn.Module):\n","    '''apply residual connection to\n","    1) preserve original information\n","    2) prevent gradient vanishing\n","    '''\n","    def __init__(self, size, dropout):\n","        super().__init__()\n","        self.norm = LayerNorm(size)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x, sublayer):\n","        return self.norm(x + self.dropout(sublayer(x)))"],"metadata":{"id":"gqpMfrDd4aOJ","executionInfo":{"status":"ok","timestamp":1701157385798,"user_tz":-540,"elapsed":2,"user":{"displayName":"이태후","userId":"03468433647806446322"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["class Encoder(nn.Module):\n","    '''Single Encoder layer\n","    input : embedded src with positional encoding\n","    output : hidden representations z (applied multi-head attention, feed-forward)\n","    '''\n","    def __init__(self, layer, N):\n","        super().__init__()\n","        self.layers = clones(layer, N)\n","        self.norm = LayerNorm(layer)"],"metadata":{"id":"encogTkY4d9f","executionInfo":{"status":"ok","timestamp":1701157398143,"user_tz":-540,"elapsed":2,"user":{"displayName":"이태후","userId":"03468433647806446322"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["class EncoderLayer(nn.Module):\n","    '''Core of encoder : self-attention -> feed forward'''\n","    def __init__(self, size, self_att, ff, dropout):\n","        super().__init__()\n","        self.self_att = self_att\n","        self.ff = ff\n","        self.sublayer = clones(ResConnection(size, dropout), 2) # self-attention, ff 둘 다 layernorm(residual connection) 적용하기 위함\n","        self.size = size\n","\n","    def forward(self, x, mask):\n","        x = self.sublayer[0](x, lambda x: self.self_att(x,x,x,mask)) # query, key, value\n","        return self.sublayer[1](x, self.ff)"],"metadata":{"id":"JL1h2MoM4gJx","executionInfo":{"status":"ok","timestamp":1701157408539,"user_tz":-540,"elapsed":2,"user":{"displayName":"이태후","userId":"03468433647806446322"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["class Decoder(nn.Module):\n","    '''N-layer decoder with masked attention'''\n","    def __init__(self, layer, N):\n","        super().__init__()\n","        self.layers = clones(layer, N)\n","        self.norm = LayerNorm(layer.size)\n","\n","    def forward(self, x, memory, src_mask, tar_mask):\n","        for layer in self.layers:\n","            x = layer(x, memory, src_mask, tar_mask)\n","        return self.norm(x)"],"metadata":{"id":"WFe041Bd4i3v","executionInfo":{"status":"ok","timestamp":1701157418427,"user_tz":-540,"elapsed":1,"user":{"displayName":"이태후","userId":"03468433647806446322"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["class DecoderLayer(nn.Module):\n","    def __init__(self, size, self_att, src_att, ff, dropout):\n","        super().__init__()\n","        self.size = size\n","        self.self_att = self_att\n","        self.src_att = src_att\n","        self.ff = ff\n","        self.sublayer = clones(ResConnection(size, dropout), 3) # masked self-att, self-att, ff 모두 layernorm(residual connection) 적용\n","\n","    def forward(self, x, memory, src_mask, tar_mask):\n","        x = self.sublayer[0](x, lambda x: self.self_att(x,x,x,tar_mask))\n","        x = self.sublayer[1](x, lambda x: self.src_att(x, memory, memory, src_mask))\n","        return self.sublayer[2](x, self.ff)"],"metadata":{"id":"Y-ZAn4aR4jlG","executionInfo":{"status":"ok","timestamp":1701157423746,"user_tz":-540,"elapsed":4,"user":{"displayName":"이태후","userId":"03468433647806446322"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":["from torch import nn\n","from torch.nn.functional import log_softmax\n","\n","class Generator(nn.Module):\n","    '''Standard linear + softmax generation step'''\n","    def __init__(self, d_model, vocab):\n","        super().__init__()\n","        self.proj = nn.Linear(d_model, vocab)\n","\n","    def forward(self, x):\n","        return log_softmax(self.proj(x), dim=-1)"],"metadata":{"id":"eSBXzVPG4nD_","executionInfo":{"status":"ok","timestamp":1701157435664,"user_tz":-540,"elapsed":2,"user":{"displayName":"이태후","userId":"03468433647806446322"}}},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":["## Full Model"],"metadata":{"id":"Q8dEs64w2ut4"}},{"cell_type":"code","source":["def make_model(\n","    src_vocab, tar_vocab, N=6, d_model=512, d_inner=2048, h=8, dropout=0.1\n","):\n","  attn = MultiHeadAttention(h, d_model)\n","  ff = PositionwiseFeedForward(d_model, d_inner, dropout)\n","  position = PositionalEncoding(d_model, dropout)\n","\n","  model = EncoderDecoder(\n","      Encoder(EncoderLayer(size=d_model, self_att=copy.deepcopy(attn), ff=copy.deepcopy(ff), dropout=dropout), N),\n","      Decoder(DecoderLayer(size=d_model, self_att=copy.deepcopy(attn), src_att=copy.deepcopy(attn), ff=copy.deepcopy(ff), dropout=dropout), N),\n","      nn.Sequential(Embeddings(src_vocab, d_model), copy.deepcopy(position)),\n","      nn.Sequential(Embeddings(tar_vocab, d_model), copy.deepcopy(position)),\n","      Generator(d_model, tar_vocab)\n","      )\n","\n","  for p in model.parameters():\n","    if p.dim() > 1:\n","      nn.init.xavier_uniform_(p)\n","\n","  return model"],"metadata":{"id":"ZdZvoW_B2tuE","executionInfo":{"status":"ok","timestamp":1701158092152,"user_tz":-540,"elapsed":3,"user":{"displayName":"이태후","userId":"03468433647806446322"}}},"execution_count":53,"outputs":[]}]}